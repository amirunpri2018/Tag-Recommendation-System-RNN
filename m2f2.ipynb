{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "import numpy as np\n",
    "import itertools\n",
    "from more_itertools import locate\n",
    "from gensim.models import FastText\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Read preprocessed train_paras.txt and tags.pkl\n",
    "    #Read pre-processed train_paras.txt\n",
    "    with open('train_paras.txt','r') as f:\n",
    "        paras=f.readlines()\n",
    "\n",
    "    for i in range(0,len(paras)):\n",
    "        paras[i]=paras[i][2:].split(\"', '\")\n",
    "        paras[i][-1]=paras[i][-1].replace(\"']\\n\",'')\n",
    "    \n",
    "    #Read pre-processed tags.pkl\n",
    "    with open(\"tags.pkl\", \"rb\") as fp:\n",
    "        tags = pickle.load(fp)\n",
    "    \n",
    "    #Set it to True to build a fasttext model\n",
    "    if False:\n",
    "        fast_text_model(paras)\n",
    "    \n",
    "    #Set it to True to build a Word2Vec model\n",
    "    if False:\n",
    "        model_wv=word2vec_model(paras)\n",
    "    \n",
    "    #Load already built Word2vec model\n",
    "    model_wv = Word2Vec.load('word2vec.model')\n",
    "    \n",
    "    #Call tags_preprocessing()\n",
    "    new_tags=tags_preprocessing(tags)\n",
    "    \n",
    "    #Call new_target()\n",
    "    new_target(new_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_text_model(paras):\n",
    "    #Building Fasttext model and save\n",
    "    model_ft = FastText(paras, size=150, window=5, min_count=3)\n",
    "    model_ft.save('fasttext.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_model(paras):\n",
    "    #Building Word2vec model and save\n",
    "    model_wv=Word2Vec(paras,size=150,window=6,min_count=3,iter=40)\n",
    "    model_wv.save('word2vec.model')\n",
    "    return model_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_preprocessing(tags):\n",
    "    # Split tags based on them having any hyphens. They're split into multiple classes and then new tags are created\n",
    "    new_tags=[]\n",
    "    #creating special new tags for '-' separated tags. Ex: bit-manipulation is \n",
    "    #transformed to $bit, $manipulation.\n",
    "    \n",
    "    for i in range(0,len(tags)):\n",
    "        tag=[]\n",
    "        for j in range(0,len(tags[i])):\n",
    "            sp=tags[i][j].split('-')\n",
    "            \n",
    "            #if two words are joined by '-' in tag then '$' is added to each sub tag\n",
    "            if len(sp)==2:\n",
    "                tag.append('$'+sp[0])\n",
    "                tag.append('$'+sp[1])\n",
    "            \n",
    "            #if three words are joined by '-' in tag then '#' is added to each sub tag\n",
    "            elif len(sp)==3:\n",
    "                tag.append('#'+sp[0])\n",
    "                tag.append('#'+sp[1])\n",
    "                tag.append('#'+sp[2])\n",
    "            else:\n",
    "                tag.append(sp[0])\n",
    "        \n",
    "        new_tags.append(tag)\n",
    "    \n",
    "    #return new tags\n",
    "    return new_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagger(value,word):\n",
    "    temp = []\n",
    "    #Search for 10 most similar word2vec words\n",
    "    try:\n",
    "        values = [i[0] for i in model_wv.wv.most_similar(word)]\n",
    "    except KeyError:\n",
    "        return []\n",
    "    \n",
    "    #Find if tag\n",
    "    for i in range(10):\n",
    "        temp.append(list(locate(paras[value], lambda x: x == values[i])))\n",
    "    \n",
    "    return list(itertools.chain.from_iterable(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_target(new_tags):\n",
    "    # Create numeric encoding for each of the tags. \n",
    "    \n",
    "    target=[]\n",
    "    \n",
    "    #Creating numeric target for each tag.\n",
    "    for i in range(0,len(new_tags)):\n",
    "        \n",
    "        #Creating a target for each word in the para\n",
    "        target_temp = np.array([0] * len(paras[i]))\n",
    "        \n",
    "        #For each tag in all the tags corresponding to a para\n",
    "        for j in range(0,len(new_tags[i])):\n",
    "            \n",
    "            #if tag contains '$' and any word in para matches with top 10 similar words\n",
    "            #of tag then target is codes as 3\n",
    "            if new_tags[i][j][0]=='$':\n",
    "                temp=list(locate(paras[i], lambda x: x == new_tags[i][j][1:]))\n",
    "                target_temp[temp]=3\n",
    "            \n",
    "            #if tag contains '#' and any word in para matches with top 10 similar words\n",
    "            #of tag then target is codes as 4\n",
    "            elif new_tags[i][j][0]=='#':\n",
    "                temp=list(locate(paras[i], lambda x: x == new_tags[i][j][1:]))\n",
    "                target_temp[temp]=4\n",
    "            \n",
    "            #if tag doesn't contain any special symbol\n",
    "            else:\n",
    "                \n",
    "                #search for any word in para matching with top 10 similar words of tag\n",
    "                #then target is codes as 2\n",
    "                temp=list(locate(paras[i], lambda x: x == new_tags[i][j]))\n",
    "                \n",
    "                #If word in para is from any of top 10 similar words of tag\n",
    "                if len(temp)==0:\n",
    "                    temp = tagger(i,new_tags[i][j])\n",
    "                    target_temp[temp] = 2\n",
    "                \n",
    "                #If word in para is exactly the tag itself\n",
    "                else:\n",
    "                    target_temp[temp]=1\n",
    "        \n",
    "        target.append(target_temp)\n",
    "    \n",
    "    #New target needs to be one hot encoded for building the model.\n",
    "    one_hot_target_create(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_target_create(target):\n",
    "    \n",
    "    # Creating an encoding for each of the tag. Whether it is present as a single word or as hyphenated words\n",
    "    \n",
    "    final_target = []\n",
    "\n",
    "    #For each sequence in the target\n",
    "    for i in range(len(target)):\n",
    "        \n",
    "        #For each tag corresponding to each word in para\n",
    "        feed_target = np.zeros([len(target[i]),5])\n",
    "        \n",
    "        #One hot encoding\n",
    "        for j in range(len(target[i])):\n",
    "            if target[i][j] == 0:\n",
    "                feed_target[j][0] = 1\n",
    "            if target[i][j] == 1:\n",
    "                feed_target[j][1] = 1\n",
    "            if target[i][j] == 2:\n",
    "                feed_target[j][2] = 1\n",
    "            if target[i][j] == 3:\n",
    "                feed_target[j][3] = 1\n",
    "            if target[i][j] == 4:\n",
    "                feed_target[j][4] = 1\n",
    "        final_target.append(feed_target)\n",
    "    \n",
    "    #Writing one hot target to file for furthur model building\n",
    "    with open(\"one_hot_target.txt\", \"w\") as f:\n",
    "        for s in final_target:\n",
    "            for k in s:\n",
    "                f.write(str(k) +\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
